{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "from category_encoders import CountEncoder\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\egesc\\anaconda3\\lib\\site-packages (2.6.4)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (1.11.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (0.14.0)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (3.5.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade category_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\egesc\\anaconda3\\lib\\site-packages (2.6.4)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (1.11.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (0.14.0)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (3.5.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\egesc\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install category_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>VisitFrequency</th>\n",
       "      <th>AverageSpend</th>\n",
       "      <th>PreferredCuisine</th>\n",
       "      <th>TimeOfVisit</th>\n",
       "      <th>GroupSize</th>\n",
       "      <th>DiningOccasion</th>\n",
       "      <th>MealType</th>\n",
       "      <th>OnlineReservation</th>\n",
       "      <th>DeliveryOrder</th>\n",
       "      <th>LoyaltyProgramMember</th>\n",
       "      <th>WaitTime</th>\n",
       "      <th>ServiceRating</th>\n",
       "      <th>FoodRating</th>\n",
       "      <th>AmbianceRating</th>\n",
       "      <th>HighSatisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1457</td>\n",
       "      <td>34</td>\n",
       "      <td>Female</td>\n",
       "      <td>138842</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>162.954929</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>8</td>\n",
       "      <td>Celebration</td>\n",
       "      <td>Dine-in</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.228618</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1371</td>\n",
       "      <td>54</td>\n",
       "      <td>Male</td>\n",
       "      <td>98671</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>66.918873</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>4</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.247186</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1505</td>\n",
       "      <td>47</td>\n",
       "      <td>Male</td>\n",
       "      <td>122351</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>94.127670</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>7</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.174873</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1011</td>\n",
       "      <td>38</td>\n",
       "      <td>Male</td>\n",
       "      <td>78868</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>92.705568</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "      <td>Business</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.237746</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1016</td>\n",
       "      <td>50</td>\n",
       "      <td>Female</td>\n",
       "      <td>128686</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>166.931144</td>\n",
       "      <td>American</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>8</td>\n",
       "      <td>Business</td>\n",
       "      <td>Dine-in</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.319628</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Age  Gender  Income VisitFrequency  AverageSpend  \\\n",
       "0        1457   34  Female  138842         Weekly    162.954929   \n",
       "1        1371   54    Male   98671         Rarely     66.918873   \n",
       "2        1505   47    Male  122351        Monthly     94.127670   \n",
       "3        1011   38    Male   78868         Weekly     92.705568   \n",
       "4        1016   50  Female  128686        Monthly    166.931144   \n",
       "\n",
       "  PreferredCuisine TimeOfVisit  GroupSize DiningOccasion  MealType  \\\n",
       "0           Indian      Dinner          8    Celebration   Dine-in   \n",
       "1           Indian       Lunch          4         Casual  Takeaway   \n",
       "2           Indian       Lunch          7         Casual  Takeaway   \n",
       "3          Mexican      Dinner          4       Business  Takeaway   \n",
       "4         American      Dinner          8       Business   Dine-in   \n",
       "\n",
       "   OnlineReservation  DeliveryOrder  LoyaltyProgramMember   WaitTime  \\\n",
       "0                  1              0                     1   4.228618   \n",
       "1                  0              0                     0  50.247186   \n",
       "2                  0              1                     0  10.174873   \n",
       "3                  0              0                     1  14.237746   \n",
       "4                  0              0                     0  56.319628   \n",
       "\n",
       "   ServiceRating  FoodRating  AmbianceRating  HighSatisfaction  \n",
       "0              1           5               3                 1  \n",
       "1              1           2               2                 0  \n",
       "2              3           3               5                 0  \n",
       "3              4           1               4                 0  \n",
       "4              4           3               4                 0  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../data/raw/train.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID                int64\n",
      "Age                       int64\n",
      "Gender                   object\n",
      "Income                    int64\n",
      "VisitFrequency           object\n",
      "AverageSpend            float64\n",
      "PreferredCuisine         object\n",
      "TimeOfVisit              object\n",
      "GroupSize                 int64\n",
      "DiningOccasion           object\n",
      "MealType                 object\n",
      "OnlineReservation         int64\n",
      "DeliveryOrder             int64\n",
      "LoyaltyProgramMember      int64\n",
      "WaitTime                float64\n",
      "ServiceRating             int64\n",
      "FoodRating                int64\n",
      "AmbianceRating            int64\n",
      "HighSatisfaction          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID\n",
      "Gender,VisitFrequency,PreferredCuisine,TimeOfVisit,DiningOccasion,MealType\n"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../pipeline.cfg')\n",
    "valor = config.get('GENERAL', 'VARS_TO_DROP')\n",
    "valor2 = config.get('CATEGORICAL', 'LABEL_ENCODER')\n",
    "print(valor)\n",
    "print(valor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature = dataset.drop(labels=list(config.get('GENERAL', 'VARS_TO_DROP').split(',')), axis=1)\n",
    "y_target = dataset[config.get('GENERAL', 'TARGET')]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_feature, y_target, test_size=0.3, shuffle=True, random_state=2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## de nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CustomerID', 'Age', 'Gender', 'Income', 'VisitFrequency',\n",
      "       'AverageSpend', 'PreferredCuisine', 'TimeOfVisit', 'GroupSize',\n",
      "       'DiningOccasion', 'MealType', 'OnlineReservation', 'DeliveryOrder',\n",
      "       'LoyaltyProgramMember', 'WaitTime', 'ServiceRating', 'FoodRating',\n",
      "       'AmbianceRating', 'HighSatisfaction'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataset.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [col.strip() for col in config.get('GENERAL', 'VARS_TO_DROP').split(',')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna 'CostumerID' no está presente\n"
     ]
    }
   ],
   "source": [
    "if 'CostumerID' in dataset.columns:\n",
    "    print(\"La columna 'CostumerID' está presente\")\n",
    "else:\n",
    "    print(\"La columna 'CostumerID' no está presente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna 'CustomerID' está presente.\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = list(config.get('GENERAL', 'VARS_TO_DROP').split(','))\n",
    "# Verificar si la columna está en el dataset\n",
    "for col in columns_to_drop:\n",
    "    if col in dataset.columns:\n",
    "        print(f\"La columna '{col}' está presente.\")\n",
    "    else:\n",
    "        print(f\"La columna '{col}' no está presente.\")\n",
    "\n",
    "# Eliminar las columnas si existen\n",
    "x_feature = dataset.drop(labels=columns_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [col.strip() for col in config.get('GENERAL', 'VARS_TO_DROP').split(',')]\n",
    "cols_to_drop = [col for col in cols_to_drop if col in dataset.columns]  # Verifica que la columna exista\n",
    "\n",
    "x_feature = dataset.drop(labels=cols_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature = dataset.drop(labels=list(config.get('GENERAL', 'VARS_TO_DROP').split(',')), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Leer el dataset\n",
    "dataset = pd.read_csv('../data/raw/train.csv')\n",
    "\n",
    "# Leer el archivo de configuración\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../pipeline.cfg')\n",
    "\n",
    "# Obtener columnas a eliminar de la configuración y limpiar espacios\n",
    "cols_to_drop = [col.strip() for col in config.get('GENERAL', 'VARS_TO_DROP').split(',')]\n",
    "\n",
    "# Verificar si las columnas a eliminar están en el DataFrame\n",
    "cols_to_drop = [col for col in cols_to_drop if col in dataset.columns]\n",
    "\n",
    "# Eliminar las columnas que existen\n",
    "x_feature = dataset.drop(labels=cols_to_drop, axis=1)\n",
    "\n",
    "# Obtener la variable objetivo\n",
    "y_target = dataset[config.get('GENERAL', 'TARGET')]\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_feature, y_target, test_size=0.3, shuffle=True, random_state=2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones: [1 0 1 1 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definir las columnas numéricas y categóricas\n",
    "categorical_columns = ['Gender', 'VisitFrequency', 'PreferredCuisine', 'TimeOfVisit', 'DiningOccasion', 'MealType']\n",
    "numeric_columns = ['Age', 'Income', 'AverageSpend', 'GroupSize', 'WaitTime', 'ServiceRating', 'FoodRating', 'AmbianceRating']\n",
    "\n",
    "# Crear el preprocesador con imputación y codificación para columnas categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numeric_columns),  # Imputación de columnas numéricas\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputación para valores nulos en categóricos\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))   # Codificación OneHot para las columnas categóricas\n",
    "        ]), categorical_columns)  # Aplicar a las columnas categóricas\n",
    "    ])\n",
    "\n",
    "# Definir el pipeline con el preprocesador y el clasificador\n",
    "restaurante_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=2025))\n",
    "])\n",
    "\n",
    "# Ajustar el modelo con los datos de entrenamiento\n",
    "restaurante_model.fit(x_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = restaurante_model.predict(x_test)\n",
    "print(f\"Predicciones: {y_pred[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Gender: ['Female' 'Male']\n",
      "Valores únicos en VisitFrequency: ['Weekly' 'Rarely' 'Monthly' 'Daily']\n",
      "Valores únicos en PreferredCuisine: ['Indian' 'Mexican' 'American' 'Chinese' 'Italian']\n",
      "Valores únicos en TimeOfVisit: ['Dinner' 'Lunch' 'Breakfast']\n",
      "Valores únicos en DiningOccasion: ['Celebration' 'Casual' 'Business']\n",
      "Valores únicos en MealType: ['Dine-in' 'Takeaway']\n"
     ]
    }
   ],
   "source": [
    "# Revisar los valores únicos en las columnas categóricas\n",
    "for column in categorical_columns:\n",
    "    print(f\"Valores únicos en {column}: {dataset[column].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones: [1 0 1 1 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definir las columnas numéricas y categóricas\n",
    "categorical_columns = ['Gender', 'VisitFrequency', 'PreferredCuisine', 'TimeOfVisit', 'DiningOccasion', 'MealType']\n",
    "numeric_columns = ['Age', 'Income', 'AverageSpend', 'GroupSize', 'WaitTime', 'ServiceRating', 'FoodRating', 'AmbianceRating']\n",
    "\n",
    "# Crear el preprocesador con imputación y codificación para columnas categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numeric_columns),  # Imputación de columnas numéricas\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputación para valores nulos en categóricos\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))   # Codificación OneHot para las columnas categóricas\n",
    "        ]), categorical_columns)  # Aplicar a las columnas categóricas\n",
    "    ])\n",
    "\n",
    "# Definir el pipeline con el preprocesador y el clasificador\n",
    "restaurante_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=2025))\n",
    "])\n",
    "\n",
    "# Ajustar el modelo con los datos de entrenamiento\n",
    "restaurante_model.fit(x_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = restaurante_model.predict(x_test)\n",
    "print(f\"Predicciones: {y_pred[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Gender: ['Female' 'Male']\n",
      "Valores únicos en VisitFrequency: ['Weekly' 'Rarely' 'Monthly' 'Daily']\n",
      "Valores únicos en PreferredCuisine: ['Indian' 'Mexican' 'American' 'Chinese' 'Italian']\n",
      "Valores únicos en TimeOfVisit: ['Dinner' 'Lunch' 'Breakfast']\n",
      "Valores únicos en DiningOccasion: ['Celebration' 'Casual' 'Business']\n",
      "Valores únicos en MealType: ['Dine-in' 'Takeaway']\n"
     ]
    }
   ],
   "source": [
    "# Revisar los valores únicos en las columnas categóricas\n",
    "for column in categorical_columns:\n",
    "    print(f\"Valores únicos en {column}: {dataset[column].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones: [1 0 1 1 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definir las columnas numéricas y categóricas\n",
    "categorical_columns = ['Gender', 'VisitFrequency', 'PreferredCuisine', 'TimeOfVisit', 'DiningOccasion', 'MealType']\n",
    "numeric_columns = ['Age', 'Income', 'AverageSpend', 'GroupSize', 'WaitTime', 'ServiceRating', 'FoodRating', 'AmbianceRating']\n",
    "\n",
    "# Crear el preprocesador con imputación y codificación para columnas categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numeric_columns),  # Imputación de columnas numéricas\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputación para valores nulos en categóricos\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))   # Codificación OneHot para las columnas categóricas\n",
    "        ]), categorical_columns)  # Aplicar a las columnas categóricas\n",
    "    ])\n",
    "\n",
    "# Definir el pipeline con el preprocesador y el clasificador\n",
    "restaurante_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=2025))\n",
    "])\n",
    "\n",
    "# Ajustar el modelo con los datos de entrenamiento\n",
    "restaurante_model.fit(x_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = restaurante_model.predict(x_test)\n",
    "print(f\"Predicciones: {y_pred[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas\n",
    "continous_columns = ['Age', 'Income', 'AverageSpend', 'GroupSize', 'WaitTime', 'ServiceRating', 'FoodRating', 'AmbianceRating']\n",
    "categorical_columns = ['Gender', 'VisitFrequency', 'PreferredCuisine', 'TimeOfVisit', 'DiningOccasion', 'MealType']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.96\n",
      "Matriz de Confusión:\n",
      "[[273  14]\n",
      " [  8 251]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Definir las columnas categóricas y continuas\n",
    "continous_columns = ['Age', 'Income', 'AverageSpend', 'GroupSize', 'WaitTime', 'ServiceRating', 'FoodRating', 'AmbianceRating']\n",
    "categorical_columns = ['Gender', 'VisitFrequency', 'PreferredCuisine', 'TimeOfVisit', 'DiningOccasion', 'MealType']\n",
    "\n",
    "# Crear un preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Imputación de variables continuas (Media)\n",
    "        ('continues_var_imputation', SimpleImputer(strategy='mean'), continous_columns),\n",
    "        # Imputación de variables categóricas (Frecuencia más común)\n",
    "        ('categorical_var_imputacion', SimpleImputer(strategy='most_frequent'), categorical_columns),\n",
    "        # Codificación de variables categóricas con OneHotEncoder\n",
    "        ('categorical_encode_ohe', OneHotEncoder(drop='first'), categorical_columns),\n",
    "        # Escalado de características continuas\n",
    "        ('feature_scaling', StandardScaler(), continous_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Función para codificación por frecuencia manual\n",
    "def frequency_encoding(df, categorical_columns):\n",
    "    for col in categorical_columns:\n",
    "        freq_map = df[col].value_counts() / len(df)  # Contar la frecuencia de cada valor\n",
    "        df[col] = df[col].map(freq_map)  # Sustituir cada valor por su frecuencia\n",
    "    return df\n",
    "\n",
    "# Aplicar la codificación por frecuencia\n",
    "x_feature = frequency_encoding(x_feature, categorical_columns)\n",
    "\n",
    "# Crear el pipeline con el modelo RandomForest\n",
    "restaurante_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=2025))\n",
    "])\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_feature, y_target, test_size=0.3, shuffle=True, random_state=2025)\n",
    "\n",
    "# Ajustar el modelo\n",
    "restaurante_model.fit(x_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = restaurante_model.predict(x_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión: {accuracy:.2f}\")\n",
    "\n",
    "# Evaluar la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Listas de columnas\n",
    "continous_columns = ['Age', 'Income', 'AverageSpend', 'GroupSize', 'WaitTime', 'ServiceRating', 'FoodRating', 'AmbianceRating']\n",
    "categorical_columns = ['Gender', 'VisitFrequency', 'PreferredCuisine', 'TimeOfVisit', 'DiningOccasion', 'MealType']\n",
    "\n",
    "# Preprocesador con imputación y codificación\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('continues_var_imputation', SimpleImputer(strategy='mean'), continous_columns),\n",
    "        ('categorical_var_imputacion', SimpleImputer(strategy='most_frequent'), categorical_columns),\n",
    "        ('categorical_encode_ohe', OneHotEncoder(drop='first'), categorical_columns),\n",
    "        ('feature_scaling', StandardScaler(), continous_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Crear el modelo en un pipeline\n",
    "restaurante_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=2025))\n",
    "])\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_feature, y_target, test_size=0.3, shuffle=True, random_state=2025)\n",
    "\n",
    "# Ajustar el modelo\n",
    "restaurante_model.fit(x_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = restaurante_model.predict(x_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocessor': ColumnTransformer(transformers=[('continues_var_imputation', SimpleImputer(),\n",
      "                                 ['Age', 'Income', 'AverageSpend', 'GroupSize',\n",
      "                                  'WaitTime', 'ServiceRating', 'FoodRating',\n",
      "                                  'AmbianceRating']),\n",
      "                                ('categorical_var_imputacion',\n",
      "                                 SimpleImputer(strategy='most_frequent'),\n",
      "                                 ['Gender', 'VisitFrequency',\n",
      "                                  'PreferredCuisine', 'TimeOfVisit',\n",
      "                                  'DiningOccasion', 'MealType']),\n",
      "                                ('categorical_encode_ohe',\n",
      "                                 OneHotEncoder(drop='first'),\n",
      "                                 ['Gender', 'VisitFrequency',\n",
      "                                  'PreferredCuisine', 'TimeOfVisit',\n",
      "                                  'DiningOccasion', 'MealType']),\n",
      "                                ('feature_scaling', StandardScaler(),\n",
      "                                 ['Age', 'Income', 'AverageSpend', 'GroupSize',\n",
      "                                  'WaitTime', 'ServiceRating', 'FoodRating',\n",
      "                                  'AmbianceRating'])]), 'classifier': RandomForestClassifier(random_state=2025)}\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los pasos del pipeline\n",
    "print(titanic_survived_model.named_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1\n",
      " 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0\n",
      " 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0\n",
      " 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 1 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0\n",
      " 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 0 1\n",
      " 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0\n",
      " 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en el conjunto de test\n",
    "y_pred = restaurante_model.predict(x_test)\n",
    "\n",
    "# Mostrar las predicciones\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9597069597069597\n",
      "Precision: 0.9471698113207547\n",
      "Recall: 0.9691119691119691\n",
      "F1 Score: 0.9580152671755725\n",
      "Confusion Matrix:\n",
      "[[273  14]\n",
      " [  8 251]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Suponiendo que y_test contiene las etiquetas verdaderas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
